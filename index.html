<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Dolphins"/>
  <meta property="og:description" content="Dolphins: A Multi-Modal Driving Model for Zero and Few-shot (In-context) Learning"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  



  <meta name="twitter:title" content="Dolphins">
  <meta name="twitter:description" content="Dolphins: A Multi-Modal Driving Model for Zero and Few-shot (In-context) Learning">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>VLM-Driver</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">-->

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Dolphins: A Multi-Modal Driving Model for Zero and Few-shot (In-context) Learning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
            <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://gray311.github.io/" target="_blank">Yingzi Ma<sup>*</sup></a><sup>1,2</sup>,&nbsp;</span>
                <!--<span class="author-block">
                  <a href="https://sites.google.com/view/hbansal" target="_blank">Hritik Bansal<sup>*</sup></a><sup>3</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://jmhessel.com/" target="_blank">Jack Hessel<sup>*</sup></a><sup>4</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://rulinshao.github.io/" target="_blank">Rulin Shao</a><sup>5</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://wanrong-zhu.com/" target="_blank">Wanrong Zhu</a><sup>6</sup>,&nbsp;</span><br>
                <span class="author-block">
                  <a href="https://anas-awadalla.streamlit.app/" target="_blank">Anas Awadalla</a><sup>5</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://homes.cs.washington.edu/~jpgard/" target="_blank">Josh Gardner</a><sup>5</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://www.rohantaori.com/" target="_blank">Rohan Taori</a><sup>7</sup>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://people.csail.mit.edu/ludwigs/" target="_blank">Ludwig Schmidt</a><sup>4,5,8</sup>&nbsp;</span>-->
                </div>

                <div class="is-size-5 publication-authors">
                  <span class="author-block"><sup>1</sup> Sichuan University,&nbsp;&nbsp;</span>
                  <!--<span class="author-block"><sup>2</sup> Google Research,&nbsp;&nbsp;</span>    
                  <span class="author-block"><sup>3</sup> University of California Los Angeles,&nbsp;&nbsp;</span>
                  <span class="author-block"><sup>4</sup> Allen Institute for AI,&nbsp;&nbsp;</span>
                  <span class="author-block"><sup>5</sup> University of Washington,&nbsp;&nbsp;</span>
                  <span class="author-block"><sup>6</sup> University of California, Santa Barbara,&nbsp;&nbsp;</span>
                  <span class="author-block"><sup>7</sup> Stanford University&nbsp;&nbsp;</span>
                  <span class="author-block"><sup>8</sup> LAION</span>
                  <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>-->
                </div>


                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://github.com/vlm-driver/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/vlm-driver/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


                <!-- HuggingFace Link -->
                <!--<span class="link-block">
                  <a href=" https://huggingface.co/datasets/mlfoundations/VisIT-Bench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p style="font-size:20px">&#x1F917;</p>
                  </span>
                  <span>Dataset</span>
                </a>
              </span>-->

              <!-- HuggingFace Link -->
                <!-- <span class="link-block">
                  <a href=" https://huggingface.co/spaces/mlfoundations/VisIT-Bench-Leaderboard" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p style="font-size:20px">&#x1F917;</p>
                  </span>
                  <span>Leaderboard</span>
                </a>
              </span>-->

              <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://github.com/vlm-driver/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Video Demo</span>
                </a>
              </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper Video -->
<section class="section hero is-small is-light" style="height: 800px;">
  <div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="publication-flipped">
        <div class="content has-text-justified">
            <p style="text-align:center;">
                <iframe align="middle" width="900" height="420" src="https://www.youtube.com/embed/Pbzn79TSRO0?si=1tCNSZBb-jEx3wYl" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
               <br>
            </p>

        </div>
      </div>
    </div>
</section>

<!-- Paper abstract -->
<section class="hero is-small" style="height: 700px;">
  <div class="hero-body">
  <div class="container">
    <div class="publication-flipped">
        <div class="content has-text-justified">
            <h3 class="subtitle is-size-3-tablet has-text-left pb-3">
               <p align="center", style="margin-top: -40px; margin-bottom: -20px; font-size: 40px;">
                   <br>
                    Abstract<br>
               </p>
            </h3>
            <h3 class="subtitle is-size-5-tablet has-text-left pb-6">
               <p style="text-align:justify; line-height:150%; margin-left: -150px; margin-right: -150px; font-size: 20px">
                    The quest for fully autonomous vehicles (AVs) capable of navigating complex real-world scenarios with human-like understanding and responsiveness necessitates the convergence of advancements in artificial intelligence, robotics, and automotive engineering. In this paper, we introduce <em><b>Dolphins</b></em>, a novel vision language model architected to imbibe human-like driving abilities. <em><b>Dolphins</b></em> is adept at processing multimodal inputs comprising video (or image) data, text instructions, and historical control signals to generate informed outputs corresponding to the provided instructions. Building upon the open-sourced pretrained Vision Language Model, OpenFlamingo, we tailored <em><b>Dolphins</b></em> to the driving domain by constructing driving-specific instruction data and conducting instruction tuning. Through the utilization of the BDD-X dataset, we designed and consolidated four distinct AV tasks into <em><b>Dolphins</b></em> to foster a holistic understanding of intricate driving scenarios. The distinctive features of <em><b>Dolphins</b></em> are delineated into two primary dimensions: (1) the ability to provide a comprehensive understanding of complex and long-tailed open-world driving scenarios and solve a spectrum of AV tasks, and (2) the emergence of human-like capabilities including gradient-free rapid learning and adaptation (in-context learning), reflection and error recovery, and interpretability. 
Through an extensive evaluation on the BDD-X dataset, <em><b>Dolphins</b></em> demonstrates an emergent ability to generalize across a variety of AV tasks, enabling it to proffer fine-grained scene understanding including but not limited to various road agent attributes (e.g., a silver car with right turn light on), behaviors (e.g., yielding to pedestrians crossing the street), environmental conditions (e.g., snowy day on a busy road in a city), and to forge robust planning strategies.
Moreover, <em><b>Dolphins</b></em>'s in-context learning ability, reflection and error recovery mechanisms, and interactive conversational interface foster a robust, reliable, and user-trustworthy autonomous driving system, shedding lights on what future AVs can achieve. Through <em><b>Dolphins</b></em>, we envisage a substantial stride towards bridging the understanding gap between humans and autonomous driving systems, propelling the AV domain closer to realizing fully autonomous vehicles.
               </p>
            </h3>
        </div>
      </div>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

        <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Scenario Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding. The video features an ego car driving in a tunnel. <em><b>Dolphins</b></em> can identify the environment in which the ego car is situated and accurately determine the color of the front vehicle as well as infer the current time.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/1.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Scenario Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding. The video features an ego car driving on a snowy street. <em><b>Dolphins</b></em> can identify the environment in which the ego car is situated, the presence of the traffic light, and accurately determine the color of the passing vehicle.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/2.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Behavior Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding and behavior understanding. The video features an ego car stopping at an intersection on a rainy day. <em><b>Dolphins</b></em> comprehensively describes the environment in which the ego car is situated, the behavior of the ego car, and can infer the reasons for its behavior.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/3.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Behavior Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding and behavior understanding. The video features an ego car making a right turn. <em><b>Dolphins</b></em> can identify these contents. <s>Words</s> means hallucination.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/4.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Behavior Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding and behavior understanding. The video shows an ego car following a taxi and going through an intersection. <s>Words</s> means hallucination.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/5.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Perception (Behavior Understanding)
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>’s capability in scenario understanding and behavior understanding. The video shows an ego car driving slowly on a busy road at night. <em><b>Dolphins</b></em> can identify the ego car traveling at a slow speed and infer that the reason is that the speed of the vehicle ahead is restricting the ego car’s speed.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/perception/6.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

  </div>
</div>
</div>
</section>
<!-- End image carousel -->



<!-- Image carouse2 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>prediction</b>. The video features an ego car driving on a snowy street. <em><b>Dolphins</b></em> can predict the trajectory of the white car passing by it. Since both the white car and the ego car are traveling in the same direction on a one-way road, the trajectories of both cars temporarily overlap.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/13.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>prediction</b>. The video shows an ego car making a U-turn. <em><b>Dolphins</b></em> can predict the trajectory of the black car parked in front of it. Since the black car in front is currently parked on the side of the road, Our model predicts that the car will remain there in the future and will not be positioned in the ego car's trajectory of turning.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/14.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>planning</b>. <em><b>Dolphins</b></em> can also understand control signals and employ them to predict the speed and turn angle of the ego car next second. Additionally, We can try to have <em><b>Dolphins</b></em> make a plan for the ego car to assist the driver during driving. However, due to the lack of sufficient information, such as the map, driving destination, etc., the plan is still limited to a brief period in the future.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/15.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>planning</b>. The video features an ego car driving on a dark city street. <em><b>Dolphins</b></em> can recognize that the ego car is approaching an intersection with a red traffic light, so it plans the future behavior for the ego car, which should be to come to a stop and wait for the traffic light to turn green to pass through the intersection safely.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/17.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>planning</b>. The video features an ego car driving on a highway and a white car is parked in front of it. <em><b>Dolphins</b></em>, by assessing that the white car in front has come to a stop, plans for the future behavior of the ego car, which should involve changing lanes to the left to avoid a collision with the stationary white car.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/18.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>prediction</b> and <b>contingency planning</b>. The video shows an ego car following a taxi and going through an intersection. On one hand, <em><b>Dolphins</b></em> can predict the future behavior of the yellow taxi for a certain period. On the other hand, <em><b>Dolphins</b></em> can make reasonable contingency plans for the ego car in case the yellow taxi in front suddenly accelerates or comes to a stop.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/19.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>prediction</b> and <b>contingency planning</b>. The video features an ego car driving in a snowy sity street on a rainy day. <em><b>Dolphins</b></em> can predict the future behavior of the white van in front of it while making reasonable contingency plans for the ego car in case the white decelerates or turns right.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/20.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

       <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Prediction and Planning
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>planning</b>. The video features an ego car driving on a highway on a rainy day. <em><b>Dolphins</b></em> is asked about the information regarding the black car to the right of the ego car, and it accurately determined that the black car's lane change would not affect the ego car's trajectory because they are separated by two lanes.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/prediction_and_planning/21.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      
  </div>
</div>
</div>
</section>
<!-- End image carouse2 -->


<!-- Image carouse3 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

        <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Rapid Learning and Adaptation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            Three examples show our model enables rapid adaptation to unseen instructions through <b>in-context learning</b>. In the first two examples, <em><b>Dolphins</b></em> learns to play the role of the driver through in-context examples and can accurately describe its behavior, despite not having been trained on such instructions. The third example shows that <em><b>Dolphins</b></em> can learn common sense from in-context examples, such as not being able to judge the current time based on the light when inside a tunnel.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/in_context_learning/7.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Rapid Learning and Adaptation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
             An example showcasing <em><b>Dolphins</b></em>'s capability in <b>prediction</b> through <b>in-context learning</b>. <em><b>Dolphins</b></em> can reason for future events that have not yet happened. Through in-context examples, our model can learn to answer "What If"-style questions, to imagine the behavior of the ego car in the future by language.
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/in_context_learning/12.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

  </div>
</div>
</div>
</section>
<!-- End image carouse3 -->


<!-- Image carouse4 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Reflection and Error Recovering
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>reflection</b>. The video features an ego car driving down a snow-covered city street. The black vehicle in front of the ego car appears to want to change to the left lane, which would be positioned on the ego car's trajectory. Initially, <em><b>Dolphins</b></em> plans for the ego car to slow down and let the black car turn left. However, after being provided with information about the 'straight has the right of way' traffic rule, <em><b>Dolphins</b></em> reflects and revises the driving plan.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/reflection/22.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
           Reflection and Error Recovering
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>reflection</b>. The video shows an ego car driving through an interaction with a white car coming from the opposite direction. Initially, <em><b>Dolphins</b></em> plans for the ego car to slow down and let the white car proceed. However, after being provided with information about the human driver decision, <em><b>Dolphins</b></em> reflects and revises the driving plan.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/reflection/23.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

  </div>
</div>
</div>
</section>
<!-- End image carouse4 -->


<!-- Image carouse5 -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Interactive Conversation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>interactive conversation</b>. The video features an ego car stopping at an intersection on a rainy day. And <em><b>Dolphins</b></em> can answer various questions in terms of the weather, the traffic lights, and how they affect driving.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/conversation/8.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Interactive Conversation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>interactive conversation</b>. This video shows an ego car stopped at an intersection waiting for a red light and a pedestrian crossing a zebra crossing. We can ask <em><b>Dolphins</b></em> some questions about what it’s paying attention to at this intersection.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/conversation/9.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Interactive Conversation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>interactive conversation</b>. In this video, there are no traffic lights, so the ego car just needs to pay attention to the pedestrians.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/conversation/10.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

      <div class="item">
         <h2 class="subtitle is-size-3-tablet has-text-weight-bold has-text-centered has-background-info-light mr-0 pt-3 pb-3">
            Interactive Conversation
           </h2>
         <h3 class="subtitle is-size-4-tablet has-text-left pr-4 pl-4 pt-3 pb-3">
         <p>
            An example showcasing <em><b>Dolphins</b></em>'s capability in <b>interactive conversation</b>. This video shows an ego car driving behind a bicyclist. By conversing with <em><b>Dolphins</b></em>, we can learn how to drive safely when there are cyclists nearby. And our model can also create a tagline for this scene.
         </p>
         <p style="text-align:center;">
           <br><br>
           <img src="static/images/conversation/11.png"  style="width: 100%; height: 100%"/>
         </p>
         </h3>
      </div>

  </div>
</div>
</div>
</section>
<!-- End image carouse5 -->



<!--<script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.16.2/gradio.js"></script>-->
<!-- Youtube video -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      &lt;!&ndash; Paper video. &ndash;&gt;-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--          <div class="publication-video">-->
<!--          <h3 class="subtitle is-size-4-tablet has-text-left">-->
<!--               <p>-->
<!--                   q2d's auto-generated dialogs enable query generation models to adapt and improve for specific dialog styles, creating labeled datasets for training and evaluation.-->
<!--                   <br>T5 model predictions above/below the line show the impact of fine-tuning on MuSiQue dialogs.-->
<!--               </p>-->
<!--               <p style="text-align:center;">-->
<!--                   <br><br>-->
<!--                   <img src="static/images/q2d_5.png"  style="width: 60%; height: 60%"/>-->
<!--               </p>-->
<!--         </h3>-->
<!--          </div>-->
<!--        </div>-->

<!--      </div>-->
<!--    </div>-->
<!--</section>-->
<!-- End youtube video-->

<!-- Youtube video -->
<!--<section class="hero is-small">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h3 class="subtitle is-size-4-tablet has-background-info-light has-text-left pr-4 pl-4 pt-3 pb-3">-->
<!--      We collect <i>normal</i> (synthetic, not weird) and <i>natural</i> (non-synthetic, not weird) images to investigate the main challenge in WHOOPS!. BLIP2 model performs well on <i>non-weird</i> cases but struggles on weird ones, indicating that weirdness is the primary challenge, not synthesis.-->
<!--      </h3>-->
<!--      <div class="columns is-centered has-text-centered">-->
<!--          <div class="publication-video">-->
<!--            <iframe src="https://nlphuji-wmtis-explorer-identify.hf.space" frameborder="0" width="850" height="450"></iframe>-->
<!--          </div>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--</section>-->


<!-- Paper poster -->
<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <h2 class="title">Paper</h2>-->
<!--      <iframe  src="static/pdfs/WHOOPS_paper.pdf" width="100%" height="550">-->
<!--          </iframe>-->
<!--        -->
<!--      </div>-->
<!--    </div>-->
<!--  </section>-->
<!--End paper poster -->

<!--BibTex citation -->
<section class="section" id="BibTeX">
<div class="container is-max-desktop content">
<h2 class="title">BibTeX</h2>
<pre><code>@misc{bitton2023visitbench,
      title={VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use}, 
      author={Yonatan Bitton and Hritik Bansal and Jack Hessel and Rulin Shao and Wanrong Zhu and Anas Awadalla and Josh Gardner and Rohan Taori and Ludwig Schimdt},
      year={2023},
      eprint={2308.06595},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}</code>
</div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p style="color:gray;font-size:9.9px;">
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
  </html>
